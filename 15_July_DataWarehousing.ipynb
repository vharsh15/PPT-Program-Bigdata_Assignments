{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "881020c2",
   "metadata": {},
   "source": [
    "DAY- 8(Data Warehousing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18e310e",
   "metadata": {},
   "source": [
    "TOPIC: Data Warehousing Fundamentals\n",
    "   1. Design a data warehouse schema for a retail company that includes dimension tables for products, customers, and time. Implement the schema using a relational database management system (RDBMS) of your choice.\n",
    "   2. Create a fact table that captures sales data, including product ID, customer ID, date, and sales amount. Populate the fact table with sample data.\n",
    "   3. Write SQL queries to retrieve sales data from the data warehouse, including aggregations and filtering based on different dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448ae383",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Create the fact table\n",
    "CREATE TABLE Sales (\n",
    "    sales_id SERIAL PRIMARY KEY,\n",
    "    product_id INT,\n",
    "    customer_id INT,\n",
    "    date_id INT,\n",
    "    sales_amount DECIMAL(10, 2),\n",
    "    quantity_sold INT,\n",
    "    FOREIGN KEY (product_id) REFERENCES Products (product_id),\n",
    "    FOREIGN KEY (customer_id) REFERENCES Customers (customer_id),\n",
    "    FOREIGN KEY (date_id) REFERENCES Time (date_id)\n",
    ");\n",
    "\n",
    "-- Populate the fact table with sample data\n",
    "INSERT INTO Sales (product_id, customer_id, date_id, sales_amount, quantity_sold)\n",
    "VALUES\n",
    "    (1, 1, 1, 100.00, 2),\n",
    "    (2, 2, 1, 150.00, 3),\n",
    "    (1, 3, 2, 75.50, 1),\n",
    "    -- Additional sample data...\n",
    "    ;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f66170",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Retrieve total sales amount for each product\n",
    "SELECT p.product_name, SUM(s.sales_amount) AS total_sales_amount\n",
    "FROM Sales s\n",
    "JOIN Products p ON s.product_id = p.product_id\n",
    "GROUP BY p.product_name;\n",
    "\n",
    "-- Retrieve sales amount by year and quarter\n",
    "SELECT t.year, t.quarter, SUM(s.sales_amount) AS total_sales_amount\n",
    "FROM Sales s\n",
    "JOIN Time t ON s.date_id = t.date_id\n",
    "GROUP BY t.year, t.quarter;\n",
    "\n",
    "-- Retrieve sales amount by customer and product category for a specific month\n",
    "SELECT c.customer_name, p.category, SUM(s.sales_amount) AS total_sales_amount\n",
    "FROM Sales s\n",
    "JOIN Customers c ON s.customer_id = c.customer_id\n",
    "JOIN Products p ON s.product_id = p.product_id\n",
    "JOIN Time t ON s.date_id = t.date_id\n",
    "WHERE t.month = 'January'\n",
    "GROUP BY c.customer_name, p.category;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5a96e6",
   "metadata": {},
   "source": [
    "TOPIC: ETL and Data Integration\n",
    "  1. Design an ETL process using a programming language (e.g., Python) to extract data from a source system (e.g., CSV files), transform it by applying certain business rules or calculations, and load it into a data warehouse.\n",
    "  2. Implement the ETL process by writing code that performs the extraction, transformation, and loading steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d84d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "# Extraction\n",
    "def extract_data(csv_file_path):\n",
    "    return pd.read_csv(csv_file_path)\n",
    "\n",
    "# Transformation\n",
    "def transform_data(data):\n",
    "    # Apply business rules or calculations\n",
    "    data['transformed_column'] = data['original_column'] * 2\n",
    "    return data\n",
    "\n",
    "# Loading\n",
    "def load_data(data, connection):\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Create or truncate tables in the data warehouse\n",
    "    cursor.execute(\"DROP TABLE IF EXISTS table_name;\")\n",
    "    cursor.execute(\"CREATE TABLE table_name (column1 datatype1, column2 datatype2);\")\n",
    "\n",
    "    # Load the transformed data into the data warehouse\n",
    "    for _, row in data.iterrows():\n",
    "        insert_query = \"INSERT INTO table_name (column1, column2) VALUES (%s, %s);\"\n",
    "        values = (row['transformed_column'], row['other_column'])\n",
    "        cursor.execute(insert_query, values)\n",
    "\n",
    "    # Commit the changes and close the cursor\n",
    "    connection.commit()\n",
    "    cursor.close()\n",
    "\n",
    "# Main ETL process\n",
    "def etl_process(csv_file_path):\n",
    "    # Extract\n",
    "    extracted_data = extract_data(csv_file_path)\n",
    "\n",
    "    # Transform\n",
    "    transformed_data = transform_data(extracted_data)\n",
    "\n",
    "    # Load\n",
    "    connection = psycopg2.connect(\n",
    "        host='your_host',\n",
    "        port='your_port',\n",
    "        database='your_database',\n",
    "        user='your_username',\n",
    "        password='your_password'\n",
    "    )\n",
    "    load_data(transformed_data, connection)\n",
    "    connection.close()\n",
    "\n",
    "# Execute the ETL process\n",
    "etl_process('path_to_csv_file.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f39f049",
   "metadata": {},
   "source": [
    "TOPIC: Dimensional Modeling and Schemas\n",
    "   1. Design a star schema for a university database, including a fact table for student enrollments and dimension tables for students, courses, and time. Implement the schema using a database of your choice.\n",
    "   2. Write SQL queries to retrieve data from the star schema, including aggregations and joins between the fact table and dimension tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011003a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Retrieve total enrollment count by semester and year\n",
    "SELECT t.semester, t.year, COUNT(*) AS total_enrollments\n",
    "FROM Enrollments e\n",
    "JOIN Time t ON e.time_id = t.time_id\n",
    "GROUP BY t.semester, t.year;\n",
    "\n",
    "-- Retrieve student enrollment details along with course information\n",
    "SELECT s.student_name, c.course_name, e.grade\n",
    "FROM Enrollments e\n",
    "JOIN Students s ON e.student_id = s.student_id\n",
    "JOIN Courses c ON e.course_id = c.course_id;\n",
    "\n",
    "-- Retrieve the average grade for each course\n",
    "SELECT c.course_name, AVG(e.grade) AS average_grade\n",
    "FROM Enrollments e\n",
    "JOIN Courses c ON e.course_id = c.course_id\n",
    "GROUP BY c.course_name;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa77a880",
   "metadata": {},
   "source": [
    "TOPIC: Performance Optimization and Querying\n",
    "    1. Scenario: You need to improve the performance of your data loading process in the data warehouse. Write a Python script that implements the following optimizations:\n",
    "Utilize batch processing techniques to load data in bulk instead of individual row insertion.\n",
    "      b)  Implement multi-threading or multiprocessing to parallelize the data loading process.\n",
    "      c)  Measure the time taken to load a specific amount of data before and after implementing these optimizations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df8ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import threading\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Function to simulate data loading for a single row\n",
    "def load_data(row):\n",
    "    # Simulate data loading process\n",
    "    time.sleep(random.uniform(0.1, 0.5))\n",
    "\n",
    "# Function to load data in batches using multi-threading\n",
    "def load_data_threading(data, batch_size):\n",
    "    threads = []\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data[i:i+batch_size]\n",
    "        thread = threading.Thread(target=load_data, args=(batch,))\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "\n",
    "    # Wait for all threads to complete\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "# Function to load data in parallel using multiprocessing\n",
    "def load_data_multiprocessing(data, batch_size):\n",
    "    pool = Pool()\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data[i:i+batch_size]\n",
    "        pool.map(load_data, batch)\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "# Main script\n",
    "if __name__ == '__main__':\n",
    "    # Generate sample data\n",
    "    data = [row for row in range(1000)]\n",
    "\n",
    "    # Define batch size and number of iterations\n",
    "    batch_size = 100\n",
    "    num_iterations = 10\n",
    "\n",
    "    # Measure time taken for loading data before optimizations\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_iterations):\n",
    "        load_data(data)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken before optimizations: {end_time - start_time} seconds\")\n",
    "\n",
    "    # Measure time taken for loading data with multi-threading\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_iterations):\n",
    "        load_data_threading(data, batch_size)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken with multi-threading: {end_time - start_time} seconds\")\n",
    "\n",
    "    # Measure time taken for loading data with multiprocessing\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_iterations):\n",
    "        load_data_multiprocessing(data, batch_size)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken with multiprocessing: {end_time - start_time} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
